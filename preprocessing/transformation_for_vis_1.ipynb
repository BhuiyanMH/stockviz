{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This file contains the data transformations applied for the visualization in the first page of the website. It is assumed that the data are downloaded and stored in the 'data' directory of the root project folder. Pandas package is required for running this notebook.\n",
    "\n",
    "Author: Mahmudul Hasan Bhuiyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file paths and other necessary variables\n",
    "input_index_data_path = '../data/compounded_index.csv'\n",
    "output_index_data_path = '../data/Compounded_index_transformed.csv'\n",
    "ci_index_path = '../data/OxCGRT_latest.csv'\n",
    "wp_file_path ='../data/c2_workplace_closing.csv'\n",
    "sh_file_path ='../data/c6_stay_at_home_requirements.csv'\n",
    "tr_file_path ='../data/c8_internationaltravel.csv'\n",
    "\n",
    "type_dict = {'Open':float, 'High':float, 'Low':float}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Index data file transformations\n",
    "\n",
    "Read and clean the stock index file, create a new column named 'Avg' representing the mean of 'High' and 'Low' column. 'M' in the volume column of European index is converted to Million and for few missing values (-), a zero (0) is put."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_column(filepath):\n",
    "    data  = pd.read_csv(filepath,index_col=0, thousands=',', dtype=type_dict, parse_dates=['Date'])\n",
    "    #fix the data representation issues\n",
    "    data['Volume'] = data[data['Index'] == 'STOXX 50 EU'].Volume.str.replace(\"M\", \"\")\n",
    "    data['Volume'] = data[data['Index'] == 'STOXX 50 EU'].Volume.str.replace(\"-\", \"0\")\n",
    "    data['Volume'] = data['Volume'].astype(float)\n",
    "    data['Volume'] = data['Volume']*1000000\n",
    "    data['Volume'] = data['Volume'].astype(int)\n",
    "    data['Close'] = data['Close'].astype(float)\n",
    "    data['Avg'] = data[['High', 'Low']].mean(axis=1)\n",
    "    data['Index'] = data['Index'].str.replace(\"Hang Sang\", \"Hang Seng\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "#cread, clean and save the stock index file, create a new column named 'Avg'\n",
    "df = create_avg_column(index_data_path)\n",
    "df.to_csv(output_index_data_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations for Confinement Index\n",
    "    \n",
    "The dataset(https://github.com/OxCGRT/covid-policy-tracker) contains \n",
    "indicators(https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/codebook.md) of \n",
    "    \n",
    "    C - containment and closure policies\n",
    "    E - economic policies\n",
    "    H - health system policies\n",
    "    M - miscellaneous policies\n",
    "    \n",
    "From which, we only consider the containment indicators. It contains data for all the countries in national and state level, but we take only the national level data of respective countries of different stock indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_early_date_ci_df():\n",
    "    \n",
    "    '''\n",
    "    In the dataset, the confinement measures are available from 2020-01-01. As we have stock data\n",
    "    from September 2019, to align both the datasets, we create and add new rows from September 19 \n",
    "    where there is no restrictions.\n",
    "    '''\n",
    "    \n",
    "    early_dates = pd.date_range(start=\"2019-09-01\",end=\"2019-12-31\").strftime(\"%Y-%m-%d\").tolist()\n",
    "    \n",
    "    indices = ['Hang Seng', 'S&P 500', 'STOXX 50 EU']\n",
    "    \n",
    "    early_date_rows = []\n",
    "    \n",
    "    for date in early_dates:\n",
    "        for index in indices:\n",
    "            early_date_rows.append([date, index, 0.0])\n",
    "    \n",
    "    early_df = pd.DataFrame(early_date_rows)\n",
    "    early_df.columns = ['Date', 'Index', 'CI']\n",
    "    \n",
    "    return early_df\n",
    "\n",
    "def get_df(path):\n",
    "    \n",
    "    '''\n",
    "    Read the data, apply some transformations and return the dataframe. \n",
    "    \n",
    "    '''\n",
    "    #read the csv file\n",
    "    dateparse = lambda x: datetime.strptime(x, '%Y%m%d')\n",
    "    data  = pd.read_csv(path, parse_dates=['Date'], date_parser=dateparse, low_memory=False)\n",
    "\n",
    "    #filter only the national level data\n",
    "    data_national = data[data.Jurisdiction=='NAT_TOTAL']\n",
    "\n",
    "    #drop unnecessary columns\n",
    "    df_confinement = data_national[ ['Date'] + list(data_national.loc[:,'CountryName':'CountryCode']) + list(data_national.loc[:,'C1_School closing':'C8_International travel controls']) ]\n",
    "    \n",
    "    #filter the countries\n",
    "    countries = ['China', 'Hong Kong', 'South Korea', 'Singapore', 'Germany', 'Spain', 'France', 'Italy', 'Netherlands', 'United Kingdom', 'United States']\n",
    "    df_confinement = df_confinement[df_confinement.CountryName.isin(countries)]\n",
    "    \n",
    "    return df_confinement\n",
    "\n",
    "\n",
    "def get_index(row):\n",
    "    \n",
    "    '''\n",
    "    Given a row of the dataframe, returns the corresponding stock index.\n",
    "    '''\n",
    "    \n",
    "    index_countries = {'Hang Seng': ['China', 'Hong Kong', 'South Korea', 'Singapore'], 'STOXX 50 EU':['Germany', 'Spain', 'France', 'Italy', 'Netherlands', 'United Kingdom'], 'S&P 500':['United States']}\n",
    "    country_name = row.CountryName\n",
    "    for index in index_countries:\n",
    "        countries = index_countries[index]\n",
    "        if country_name in countries:\n",
    "            return index\n",
    "        \n",
    "\n",
    "def get_confinement_index_df(filepath, is_aligned):\n",
    "    \n",
    "    '''\n",
    "    Create a new column named as CI (Confinement Index) by averaging the values of 8 confinement indicators. \n",
    "    \n",
    "    Params:\n",
    "        filepath: path of the 'OxCGRT_latest' file\n",
    "        is_aligned: bollean variable to indicate wheather to align the data with the stock market data \n",
    "            by creating dates from September 2019 as specified before. \n",
    "\n",
    "    '''\n",
    "    \n",
    "    df = get_df(filepath)\n",
    "    \n",
    "    df = df[['Date', 'CountryName', 'CountryCode', 'C1_School closing', 'C2_Workplace closing', 'C3_Cancel public events', 'C4_Restrictions on gatherings', 'C5_Close public transport', 'C6_Stay at home requirements', 'C7_Restrictions on internal movement', 'C8_International travel controls']]\n",
    "    df['Index'] = df.apply(lambda row: get_index(row), axis=1)\n",
    "\n",
    "    df['CI'] = df.loc[:, 'C1_School closing':'C8_International travel controls'].mean(axis=1)\n",
    "    df_ci = df[['Date', 'Index', 'CI']]\n",
    "    \n",
    "    #we drop the null values \n",
    "    df_ci = df_ci.dropna()\n",
    "\n",
    "    df_ci = df_ci.groupby(['Date', 'Index']).mean()\n",
    "    df_ci.reset_index(inplace=True)\n",
    "    \n",
    "    #if data has to be alligned with the stock market data\n",
    "    if is_aligned:\n",
    "        early_df = get_early_date_ci_df()\n",
    "        df_ci = pd.concat([early_df, df_ci], ignore_index=True)\n",
    "    \n",
    "    #convert the string date to pandas date format\n",
    "    df_ci['Date'] = pd.to_datetime(df_ci['Date'], format='%Y-%m-%d')\n",
    "    \n",
    "    # We take data until the end of 2020\n",
    "    df_ci = df_ci[df_ci['Date'] < '2021-01-01']\n",
    "    df_ci = df_ci.round({'CI': 4})\n",
    "    return df_ci\n",
    "\n",
    "df = get_confinement_index_df(filepath=ci_index_path, is_aligned=True)\n",
    "df.to_csv('../data/Confinement_index_transformed.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations for Confinement Measures\n",
    "\n",
    "Although the confiment index is calculated over all the confinement indicators, to visualize the actual measures \n",
    "we only consider the most important confinement indicators representing Workplace closing(C2), Stay at home(C6) and International travel measures (C8) (https://github.com/OxCGRT/covid-policy-tracker/tree/master/data/timeseries). \n",
    "\n",
    "As there are some enforced confinement measures since the early days of Covid, instead of taking all the dates we only take the dates on which there is a change in the confinement policy. \n",
    "\n",
    "To visualize the confinement measures, we only consider the economically most important countries of EU (Germany, Spain, France, Italy, Netherlands, United Kingdom) among all the countries comprising the STOXX 50 EU index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confinement_df(path):\n",
    "    \n",
    "    '''\n",
    "    Read the file confinement file and create a dataframe with the countries under consideration.\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    #filter the countries\n",
    "    countries = ['China', 'Hong Kong', 'South Korea', 'Singapore', 'Germany', 'Spain', 'France', 'Italy', 'Netherlands', 'United Kingdom', 'United States']\n",
    "    df = df[df.country_name.isin(countries)]\n",
    "    df = df.dropna(axis=1)\n",
    "\n",
    "    df = df.T\n",
    "    df = df.iloc[3:]\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['Date', 'China', 'Germany', 'Spain', 'France', 'United Kingdom',\n",
    "       'Hong Kong', 'Italy', 'South Korea', 'Netherlands', 'Singapore',\n",
    "       'United States']\n",
    "    df['Date'] =  pd.to_datetime(df['Date'], format='%d%b%Y')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_combined_confinement_df(wp_file=wp_file_path, sh_file=sh_file_path, tr_file=tr_file_path):\n",
    "    \n",
    "    '''\n",
    "    Combines the three confinement indicator values in a dataframe and returns it\n",
    "    '''\n",
    "    \n",
    "    workplace_df = get_confinement_df(wp_file)\n",
    "    stayhome_df = get_confinement_df(sh_file)\n",
    "    travel_df = get_confinement_df(tr_file)\n",
    "    \n",
    "    combined_df = pd.DataFrame()\n",
    "    combined_df['Date'] = workplace_df.Date.copy()\n",
    "    \n",
    "    columns = workplace_df.columns.tolist()\n",
    "    columns.remove('Date')\n",
    "\n",
    "    for column in columns:\n",
    "        combined_df[column] = workplace_df[column].astype(int).apply(str)+stayhome_df[column].astype(int).apply(str)+travel_df[column].astype(int).apply(str)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def convert_text_instruction(instruction_code):\n",
    "    \n",
    "    '''\n",
    "    Convert the confinement indicator values to text measures accordign to the encoding of data source\n",
    "    '''\n",
    "\n",
    "    instruction_map = {\n",
    "        'wp':{'1':'Recommended workplace closing', '2':'Require workplace closing for some sectors', '3': 'Require closing for all but essential workplaces'},\n",
    "        'sh':{'1':'Recommended not leaving house', '2':'Require not leaving house with exceptions for essential trips', '3':'Require not leaving house with minimal exceptions'},\n",
    "        'tr':{'1':'Covid screening on arrivals', '2':'Quarantine on arrivals from some or all regions', '3':'Ban on arrivals from some regions', '4':'Ban on all regions or total border closure'}\n",
    "    }\n",
    "    \n",
    "    if instruction_code == '000':\n",
    "        return 'No restriction'\n",
    "    else:\n",
    "        wpc = instruction_code[0]\n",
    "        shc = instruction_code[1]\n",
    "        trc = instruction_code[2]\n",
    "        \n",
    "        instruction_text = ''\n",
    "        \n",
    "        #\n",
    "        if wpc != '0':\n",
    "            instruction_text += instruction_map['wp'][wpc]\n",
    "        \n",
    "        if shc != '0':\n",
    "            if instruction_text == '':\n",
    "                instruction_text += instruction_map['sh'][shc]\n",
    "            else:\n",
    "                instruction_text += '; '+instruction_map['sh'][shc]\n",
    "        \n",
    "        if trc != '0':\n",
    "            if instruction_text == '':\n",
    "                instruction_text += instruction_map['tr'][trc]\n",
    "            else:\n",
    "                instruction_text += '; '+instruction_map['tr'][trc]\n",
    "        \n",
    "    return instruction_text\n",
    "\n",
    "    \n",
    "def get_text_confinement_df():\n",
    "    \n",
    "    '''\n",
    "    Applies the function for converting the instruction code to text measures\n",
    "    '''\n",
    "    \n",
    "    df = get_combined_confinement_df()\n",
    "    columns = df.columns.tolist()\n",
    "    columns.remove('Date')\n",
    "    \n",
    "    for column in columns:\n",
    "        df[column] = df[column].apply(convert_text_instruction)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_unchanged_rows(df):\n",
    "    \n",
    "    '''\n",
    "    For visualization purpose, we only keep the dates on which there is a change in the measures.\n",
    "    This function removes the date between two measure change dates.\n",
    "    '''\n",
    "    \n",
    "    prev_row = None\n",
    "    keep_index = []\n",
    "    columns = df.columns.tolist()\n",
    "    columns.remove('Date')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        if index == 0:\n",
    "            prev_row = row\n",
    "            keep_index.append(index)\n",
    "            continue\n",
    "            \n",
    "        for col in columns:\n",
    "            if prev_row.loc[col] != row.loc[col]:\n",
    "                keep_index.append(index)\n",
    "                prev_row = row\n",
    "            break\n",
    "    \n",
    "    df = df.loc[keep_index]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_index_measure(df, index_name):\n",
    "    \n",
    "    '''\n",
    "    Combines the measures of countries corresponding to a particular stock index to a single \n",
    "    measure string. \n",
    "    '''\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append([\"2019-09-01\", index_name, \"No restriction\"])\n",
    "    \n",
    "    columns = df.columns.tolist()\n",
    "    columns.remove('Date')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        measure = \"\\n\"\n",
    "        for col in columns:\n",
    "            measure += col + \": \" + row.loc[col] + '\\n'\n",
    "        row_list.append([row.loc['Date'].strftime(\"%Y-%m-%d\"), index_name, measure])\n",
    "    \n",
    "    result_df = pd.DataFrame(row_list)\n",
    "    result_df.columns = ['Date', 'Index', 'Measure']\n",
    "    result_df['Date'] = pd.to_datetime(result_df['Date'], format='%Y-%m-%d')\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def get_indexed_measure():\n",
    "    \n",
    "    '''\n",
    "    Creates the textual confinement measures for countries of different stock indices.\n",
    "    It only cpatures the date on which there is a chaneg in the confinement rules.    \n",
    "    '''\n",
    "    \n",
    "    df = get_text_confinement_df()\n",
    "    \n",
    "    asian_index_df = df[['Date', 'China', 'Hong Kong', 'South Korea', 'Singapore']]\n",
    "    eu_index_df = df[['Date', 'Germany', 'France', 'Spain', 'Italy', 'Netherlands', 'United Kingdom']]    \n",
    "    usa_index_df = df[['Date', 'United States']]\n",
    "    \n",
    "    asian_index_df = remove_unchanged_rows(asian_index_df)\n",
    "    eu_index_df = remove_unchanged_rows(eu_index_df)   \n",
    "    usa_index_df = remove_unchanged_rows(usa_index_df)\n",
    "    \n",
    "    asian_index_df = combine_index_measure(asian_index_df, \"Hang Seng\")\n",
    "    eu_index_df = combine_index_measure(eu_index_df, \"STOXX 50 EU\")   \n",
    "    usa_index_df = combine_index_measure(usa_index_df, \"S&P 500\")\n",
    "    \n",
    "    df = pd.concat([asian_index_df, eu_index_df, usa_index_df])\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "df = get_indexed_measure()\n",
    "df.to_csv('../data/Confinement_measures_transformed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
